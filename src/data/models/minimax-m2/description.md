MiniMax-M2 is an advanced open-source large language model released by the startup MiniMax in October 2025. It's notable for being a Mixture-of-Experts (MoE) model with a focus on coding and agentic tool use. The technical details: MiniMax-M2 has 230 billion total parameters but only 10 billion active parameters per inference (meaning it uses a small subset of experts per token). This architecture allows it to achieve "frontier-level" intelligence at a dramatically lower computational cost. In fact, MiniMax-M2 is often called "the new king of open source LLMs", especially for tasks involving external tools. Key features include high intelligence ranking (#1 among open models on an aggregate intelligence index covering reasoning, coding, etc. as of late 2025), essentially matching or coming very close to proprietary giants like GPT-5 and Claude 4.5 on many benchmarks. It was specifically optimized for agent tasks – meaning it's great at planning, using tools, and executing multi-step instructions autonomously. It achieved top-tier scores in benchmarks like τ²-Bench (77.2, nearly reaching GPT-5's 80.1) and BrowseComp (a web browsing task). For coding, MiniMax-M2 scores ~69.4% on SWE-Bench Verified (just shy of GPT-5's 74.9). It not only writes code well, but can debug, explain, and integrate with developer workflows. It's particularly good at "agentic coding" – writing code that calls other tools/services. Because only 10B parameters are active, it's much more efficient to run than a dense model of similar capability. The MiniMax team boasted it can be served on as few as 4 H100 GPUs with 8-bit precision, which is remarkable for its intelligence level. This also yields lower latency and easier scaling – making it practical for enterprise deployment without a supercomputer. MiniMax-M2 was released under the MIT license (free for commercial use without many restrictions). This is huge – it means companies can use or fine-tune M2 freely in their products. Overall, MiniMax-M2 is like an open competitor to the likes of GPT-4.5/5, focused on being lightweight and agent-savvy. It's the product of a Chinese startup (MiniMax) that evidently put emphasis on practical enterprise needs: cost, speed, reliability in complex workflows.
